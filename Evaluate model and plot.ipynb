{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from os import makedirs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torch.nn.functional import sigmoid\n",
    "#Import local files\n",
    "from library.dataset import SequenceTyphoonDataset as STD\n",
    "from library.lstm_predictor import LSTM\n",
    "from library.dataset import NORMALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define necessary paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_preprocessed_path=\"C:/Users/nilss/Desktop/Advanded ML FOLDer/outputs-Typhoon_prediction/r34p_10k_w6\"\n",
    "_path_to_dataset='F:/Data folder for ML/AU/AU'\n",
    "_path_checkpoint=\"c:/Users/nilss/Desktop/Advanded ML FOLDer/outputs-Typhoon_prediction/models/ts/lstm_10kp_3l_1024_3i_pressure/checkpoint_30000.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expected model inputs: 69\n",
      "Expected model outputs: 2\n",
      "\n",
      "\n",
      "269 train sequences\n",
      "58 val sequences\n",
      "57 test sequences\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "labels_ = [\"pressure\"]\n",
    "\n",
    "if \"grade\" in labels_:\n",
    "    def filter_func(x):\n",
    "        return x.grade() < 7\n",
    "elif \"pressure\" in labels_:\n",
    "    def filter_func(x):\n",
    "        return x.grade() < 6\n",
    "\n",
    "def filter_func(x):\n",
    "    return x.grade() < 6\n",
    "# The following code calls STD is hardcoded. If arguments are changed, this needs to be changed\n",
    "dataset = STD(labels=[\"month\", \"day\", \"hour\", \"pressure\", \"wind\"],\n",
    "            preprocessed_path=_preprocessed_path,\n",
    "            x=[0,1,2,3,4],\n",
    "            y=[3,4],\n",
    "            latent_dim=len([int(x) for x in str(\"3,4\").split(\",\")]),\n",
    "            num_inputs=3,\n",
    "            num_preds=8,\n",
    "            interval=3,\n",
    "            filter_func=filter_func,\n",
    "            prefix = _path_to_dataset, # Path\n",
    "            output_all=True,\n",
    "            pred_diff=False,\n",
    "            )\n",
    "train, val, test = dataset.random_split([0.7, 0.15, 0.15], split_by=\"sequence\")\n",
    "\n",
    "print(f\"\\n{len(train)} train sequences\")\n",
    "print(f\"{len(val)} val sequences\")\n",
    "print(f\"{len(test)} test sequences\")\n",
    "\n",
    "test_loader = DataLoader(test,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,\n",
    "                        collate_fn=lambda x:x)\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Loading model from checkpoint c:/Users/nilss/Desktop/Advanded ML FOLDer/outputs-Typhoon_prediction/models/ts/lstm_10kp_3l_1024_3i_pressure/checkpoint_30000.pth\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def _load_checkpoint(model, path):\n",
    "    data = torch.load(path)\n",
    "    model.load_state_dict(data[\"model_dict\"])\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Loading model from checkpoint {path}\")\n",
    "    print(\"=\"*100)\n",
    "    return model\n",
    "\n",
    "model = LSTM(\n",
    "    test_loader.dataset.dataset.get_input_size(),\n",
    "    hidden_size=1024,\n",
    "    num_layers=3,\n",
    "    output_size=test_loader.dataset.dataset.num_preds\n",
    ")\n",
    "\n",
    "model = _load_checkpoint(model, _path_checkpoint)\n",
    "model = model.eval()\n",
    "\n",
    "device = \"cpu:0\"\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_es_transition(model, sequence, start, device):\n",
    "    if isinstance(sequence, tuple):\n",
    "        images, labels = sequence\n",
    "        inputs = images[test_loader.dataset.dataset.slice_inputs(start)]\n",
    "        outputs = labels[test_loader.dataset.dataset.slice_outputs(start), test_loader.dataset.dataset.y]\n",
    "    else:\n",
    "        inputs = sequence[test_loader.dataset.dataset.slice_inputs(start), test_loader.dataset.dataset.x]\n",
    "        outputs = sequence[test_loader.dataset.dataset.slice_outputs(start), test_loader.dataset.dataset.y]\n",
    "\n",
    "    prediction = sigmoid(model(inputs.unsqueeze(0).to(device)))[-1]\n",
    "\n",
    "    return prediction.cpu().item(), (outputs[-1]==6).float().item()\n",
    "\n",
    "\n",
    "def pressure(x):\n",
    "    return x * NORMALIZATION[\"pressure\"][1] + NORMALIZATION[\"pressure\"][0]\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_pressure(model, sequence, start, device, pred_diff):\n",
    "    # always unpack the tuple\n",
    "    images, labels = sequence\n",
    "\n",
    "    # DEBUG: \n",
    "    print(\">> predict_pressure: labels:\", type(labels), \n",
    "          getattr(labels, \"shape\", None), \n",
    "          \"len?\",  getattr(labels, \"__len__\", lambda: None)())\n",
    "\n",
    "    # build your index lists\n",
    "    idx_in  = test_loader.dataset.dataset.slice_inputs(start)\n",
    "    idx_out = test_loader.dataset.dataset.slice_outputs(start)\n",
    "    y_cols  = test_loader.dataset.dataset.y\n",
    "\n",
    "    # pull out the inputs\n",
    "    inputs = images[idx_in]                     # shape: (num_inputs, …)\n",
    "    inputs = torch.tensor(inputs).unsqueeze(0).to(device)\n",
    "\n",
    "    # pull out the ground‐truth labels\n",
    "    lab_np  = np.asarray(labels)                # ensure numpy\n",
    "    out_np  = lab_np[idx_out]                   # shape: (num_preds, n_features)\n",
    "    outputs = torch.tensor(out_np[:, y_cols])   # shape: (num_preds,)\n",
    "\n",
    "    # run the model\n",
    "    prediction = model(inputs)[-1]              # last step only\n",
    "    if pred_diff:\n",
    "        # if your model predicts a delta, add the last input value:\n",
    "        last_val = lab_np[idx_in][-1, y_cols]\n",
    "        prediction = prediction + last_val\n",
    "\n",
    "    # un‐normalize\n",
    "    return pressure(prediction.cpu().item()), pressure(outputs[-1].item())\n",
    "\n",
    "\n",
    "def smooth_ema(predictions, alpha=0.9):\n",
    "    last = predictions[0]\n",
    "    smoothed = []\n",
    "    for p in predictions:\n",
    "        smoothed.append(alpha*p + (1-alpha)*last)\n",
    "        last = smoothed[-1]\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation (GIF) of evolution of forecasting depending on input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:   0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sequences:  16%|█▌        | 9/57 [00:50<03:43,  4.66s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# shorthand to your underlying SequenceTyphoonDataset\n",
    "tds = test_loader.dataset.dataset  # type: SequenceTyphoonDataset\n",
    "\n",
    "# compute your window size once\n",
    "pred_window = (tds.num_inputs + tds.num_preds) * tds.interval\n",
    "\n",
    "all_preds = []\n",
    "all_gt    = []\n",
    "results   = []\n",
    "\n",
    "path = \"images2/lstm_10kp_pressure\"\n",
    "makedirs(path, exist_ok=True)\n",
    "\n",
    "# cache these helpers / indices\n",
    "x_idxs    = tds.x               # list of 69 input‐feature indices\n",
    "slice_in  = tds.slice_inputs\n",
    "slice_out = tds.slice_outputs\n",
    "# pick only the pressure column (index 3) instead of both [3,4]\n",
    "y_idx     = tds.y[0]            # 3\n",
    "\n",
    "for seq_idx, batch in enumerate(tqdm(test_loader, desc=\"Sequences\")):\n",
    "    # 1) unpack what Dataset returns: (latent_seq_tensor, seq_id_str)\n",
    "    latent_seq_t, seq_id = batch[0]\n",
    "\n",
    "    # 2) convert latent_seq to NumPy, drop batch‐dim\n",
    "    images_np = latent_seq_t.squeeze(0).cpu().numpy()  # shape (T, feature_dim)\n",
    "\n",
    "    # 3) fetch the true labels array by seq_id\n",
    "    labels_arr, _ = tds.get_sequence(seq_id)\n",
    "    labels_np = np.asarray(labels_arr)                 # shape (T, F)\n",
    "    if labels_np.ndim == 1:\n",
    "        labels_np = labels_np[:, None]                 # make (T,1) if needed\n",
    "\n",
    "    T = labels_np.shape[0]\n",
    "    n_windows = T - pred_window\n",
    "    if n_windows <= 0:\n",
    "        print(f\"⚠️ Seq {seq_id} too short ({T} < {pred_window}), skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 4) slide over windows and run model\n",
    "    data = []\n",
    "    for j in range(n_windows):\n",
    "        in_rows  = slice_in(j)\n",
    "        out_rows = slice_out(j)\n",
    "\n",
    "        # grab inputs (num_inputs × 69) and ground‐truth pressure (num_preds,)\n",
    "        inp_arr = labels_np[in_rows][:, x_idxs]   # (num_inputs, 69)\n",
    "        out_arr = labels_np[out_rows,  y_idx]     # (num_preds,)\n",
    "\n",
    "        # to tensor and predict\n",
    "        inp_t  = torch.tensor(inp_arr, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        pred_t = model(inp_t)                     # returns 1D tensor length num_preds\n",
    "        pred_v = pred_t[-1].item()                # last time‐step\n",
    "\n",
    "        # un‐normalize\n",
    "        pred_p = pressure(pred_v)\n",
    "        gt_p   = pressure(out_arr[-1])\n",
    "        data.append((pred_p, gt_p))\n",
    "\n",
    "    # 5) unpack & smooth\n",
    "    preds, gt_vals = zip(*data)\n",
    "    preds = smooth_ema(preds, alpha=0.5)\n",
    "\n",
    "    # 6) record performance\n",
    "    all_preds.extend(preds)\n",
    "    all_gt.extend(gt_vals)\n",
    "    seq_rmse = root_mean_squared_error(gt_vals, preds)\n",
    "    results.append((seq_id, seq_rmse))\n",
    "    \n",
    "    # 7) Finalization\n",
    "    xs_gt     = np.arange(T)\n",
    "    ys_gt     = pressure(labels_np[:, y_idx])  # full ground truth over all T frames\n",
    "\n",
    "    # Create x-values only for predictions (they begin after pred_window frames)\n",
    "    x_preds   = list(range(pred_window, pred_window + len(preds)))\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(xs_gt, ys_gt, \":\", label=\"ground truth\",color='navy')\n",
    "    plt.plot(x_preds, preds, label=\"predictions\",color='#f70d1a')\n",
    "    plt.ylim(880, 1020)\n",
    "    plt.xlabel(\"Time [hours]\", fontsize=20)\n",
    "    plt.ylabel(\"Central pressure [hPa]\", fontsize=20)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{path}/{seq_id}_{seq_rmse:.3f}.png\", transparent=True)\n",
    "\n",
    "# 8) overall\n",
    "print(\"Overall RMSE:\", root_mean_squared_error(all_gt, all_preds))\n",
    "print(\"Per-sequence RMSE (sorted):\")\n",
    "for sid, rmse in sorted(results, key=lambda x: x[1]):\n",
    "    print(f\"  {sid}: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
